{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import GloVe, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.mask = None\n",
    "\n",
    "    def set_mask(self, mask, value = float(\"-inf\")):\n",
    "        self.mask = mask\n",
    "        self.value = value\n",
    "\n",
    "    def forward(self, Q, K, V, d_k):\n",
    "        QK_T = torch.matmul(Q, torch.transpose(K, -1, -2))\n",
    "        attention_scores = torch.div(QK_T, torch.sqrt(d_k))\n",
    "\n",
    "        if self.mask is not None:\n",
    "            attention_scores.masked_fill_(self.mask, self.value)\n",
    "\n",
    "\n",
    "        softmax = F.softmax(attention_scores, dim = -1)\n",
    "        return torch.matmul(softmax, V)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, d_k: int, d_v: int, h: int):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.h = h\n",
    "        self.d_k_value = torch.Tensor([d_k])\n",
    "        self.linear = nn.ModuleList()\n",
    "        self.W_O = nn.Parameter(torch.Tensor(h*d_v, d_model))\n",
    "        self.attention = Attention()\n",
    "\n",
    "        for _ in range(self.h):\n",
    "            linear = nn.ModuleList([nn.Linear(d_k, d_model), nn.Linear(d_k, d_model), nn.Linear(d_v, d_model)])\n",
    "            self.linear.append(linear)\n",
    "\n",
    "    def init_weights(self, init_fn):\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def set_mask(self, mask, value = float(\"-inf\")):\n",
    "        self.attention.set_mask(mask, value)\n",
    "\n",
    "    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor):\n",
    "        assert len(Q.shape) == len(K.shape) == len(V.shape), f\"invalid dimensions, got Q:{Q.shape}, K: {K.shape}, V:{V.shape}\"\n",
    "\n",
    "        heads = [self.attention(layer[0](Q), layer[1](K), layer[2](V), self.d_k_value) for layer in self.linear]\n",
    "        concat_heads = torch.cat(heads, dim = -1)\n",
    "        return torch.matmul(concat_heads, self.W_O)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, intermediate_features = None):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        if intermediate_features is None:\n",
    "            self.intermediate_features = in_features*4\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, self.intermediate_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.intermediate_features, out_features)\n",
    "        )\n",
    "\n",
    "    def init_weights(self, init_fn):\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self, d_model: int, d_k: int, d_v: int, h: int):\n",
    "        super(EncoderStack, self).__init__()\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, d_k, d_v, h)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.position_wise_feed_forward = PositionWiseFeedForward(d_v, d_v)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def init_weights(self, init_fn):\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def set_mask(self, mask, value = float(\"-inf\")):\n",
    "        self.multi_head_attention.set_mask(mask, value)\n",
    "\n",
    "    def forward(self, X):\n",
    "        sublayer_1_output = self.multi_head_attention(X, X, X)\n",
    "        sublayer_1_normalised = self.layer_norm1(X + sublayer_1_output)\n",
    "        sublayer_2_output = self.position_wise_feed_forward(sublayer_1_normalised)\n",
    "        output = self.layer_norm2(sublayer_1_normalised + sublayer_2_output)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, d_model: int, d_k: int, d_v: int, h: int):\n",
    "        super(DecoderStack, self).__init__()\n",
    "\n",
    "        self.multi_head_attention1 = MultiHeadAttention(d_model, d_k, d_v, h)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.multi_head_attention2 = MultiHeadAttention(d_model, d_k, d_v, h)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.position_wise_feed_forward = PositionWiseFeedForward(d_v, d_v)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def set_mask(self, autoregressive_padding_mask, padding_mask, value = float(\"-inf\")):\n",
    "        self.multi_head_attention1.set_mask(autoregressive_padding_mask, value = value)\n",
    "        self.multi_head_attention2.set_mask(padding_mask, value = value)\n",
    "\n",
    "    def init_weights(self, init_fn):\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def forward(self, X, Q, K):\n",
    "\n",
    "        V = self.multi_head_attention1(X, X, X)\n",
    "        V_norm = self.layer_norm1(X + V)\n",
    "        sublayer_2_output = self.multi_head_attention2(Q, K, V_norm)\n",
    "        sublayer_2_normalised = self.layer_norm2(V_norm + sublayer_2_output)\n",
    "        sublayer_3_output = self.position_wise_feed_forward(sublayer_2_normalised)\n",
    "        output = self.layer_norm3(sublayer_2_normalised + sublayer_3_output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, max_len=1000, dropout = 0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough `P`\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class AttentionIsAllYouNeed(nn.Module):\n",
    "    def __init__(self, d_model: int,\n",
    "                 d_k: int,\n",
    "                 d_v: int,\n",
    "                 h: int,\n",
    "                 output: int,\n",
    "                 number_of_encoder_stacks: int,\n",
    "                 number_of_decoder_stacks: int,\n",
    "                 padding_token = None,\n",
    "                 mask_value = float(\"-inf\")):\n",
    "        super(AttentionIsAllYouNeed, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.h = h\n",
    "        self.padding_token = padding_token\n",
    "        self.mask_value = mask_value\n",
    "\n",
    "        self.cached_query = None\n",
    "        self.cached_key = None\n",
    "\n",
    "        self.autoregressive_padding_mask = None\n",
    "        self.encoder_padding_mask = None\n",
    "        self.decoder_padding_mask = None\n",
    "\n",
    "        self.embedding = None\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_list = nn.ModuleList()\n",
    "\n",
    "        for _ in range(number_of_encoder_stacks):\n",
    "            encoder_list.append(EncoderStack(d_model, d_k, d_v, h))\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_list)\n",
    "\n",
    "        self.decoder = nn.ModuleList()\n",
    "\n",
    "        for _ in range(number_of_decoder_stacks):\n",
    "            self.decoder.append(DecoderStack(d_model, d_k, d_v, h))\n",
    "\n",
    "        self.final_layer = nn.Linear(d_v, output)\n",
    "\n",
    "    def init_weights(self, init_fn):\n",
    "        self.apply(init_fn)\n",
    "\n",
    "    def init_embedding(self, pretrained_embeddings, freeze_embeddings = False, sparse = False):\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze = freeze_embeddings, sparse=sparse)\n",
    "\n",
    "    def init_state(self, Query, Key):\n",
    "       self.cached_query = Query\n",
    "       self.cached_key = Key\n",
    "\n",
    "    def clear_cache(self):\n",
    "        self.cached_query = None\n",
    "        self.cached_key = None\n",
    "\n",
    "        self.autoregressive_padding_mask = None\n",
    "        self.encoder_padding_mask = None\n",
    "        self.decoder_padding_mask = None\n",
    "\n",
    "    def create_encoder_mask(self, X):\n",
    "        token_len = X.size(1)\n",
    "\n",
    "        if self.padding_token != None:\n",
    "            padded_tokens = (X == self.padding_token)\n",
    "            padding_mask = padded_tokens.unsqueeze(1).expand(-1, token_len, -1)\n",
    "            self.encoder_padding_mask = padding_mask\n",
    "\n",
    "    def create_decoder_mask(self, X):\n",
    "        token_len = X.size(1)\n",
    "\n",
    "        self.autoregressive_padding_mask = torch.triu(torch.ones(token_len, token_len), diagonal=1).bool()\n",
    "\n",
    "        if self.padding_token != None:\n",
    "            padded_tokens = (X == self.padding_token)\n",
    "            padding_mask = padded_tokens.unsqueeze(1).expand(-1, token_len, -1)\n",
    "            self.autoregressive_padding_mask = self.autoregressive_padding_mask | padding_mask\n",
    "            self.decoder_padding_mask = padding_mask\n",
    "\n",
    "\n",
    "    def set_mask(self):\n",
    "        for stack in self.encoder:\n",
    "            stack.set_mask(self.encoder_padding_mask, self.mask_value)\n",
    "\n",
    "        if self.autoregressive_padding_mask is not None: # Indicates create_decoder_mask hasn't been called yet\n",
    "            for stack in self.decoder:\n",
    "                stack.set_mask(self.autoregressive_padding_mask, self.decoder_padding_mask, self.mask_value)\n",
    "\n",
    "    def encode(self, X, cache = True):\n",
    "        self.create_encoder_mask(X)\n",
    "        self.set_mask()\n",
    "\n",
    "        X = self.embedding(X)\n",
    "        X = self.positional_encoding(X)\n",
    "        state = self.encoder(X)\n",
    "\n",
    "        if cache:\n",
    "            self.cached_query = state\n",
    "            self.cached_key = state\n",
    "            return None\n",
    "        else:\n",
    "            return (state, state)\n",
    "\n",
    "    def decode(self, Y, Q = None, K = None):\n",
    "        self.create_decoder_mask(Y)\n",
    "        self.set_mask()\n",
    "\n",
    "        if not (Q and K):\n",
    "            assert self.cached_query is not None, \"No cached state to use\"\n",
    "            assert self.cached_key is not None, \"No cached state to use\"\n",
    "\n",
    "            Q = self.cached_query\n",
    "            K = self.cached_key\n",
    "\n",
    "\n",
    "\n",
    "        Y = self.embedding(Y)\n",
    "        Y = self.positional_encoding(Y)\n",
    "\n",
    "        for stack in self.decoder:\n",
    "            Y = stack(Y, Q, K)\n",
    "\n",
    "        Y_hat = self.final_layer(Y)\n",
    "\n",
    "        return Y_hat\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        self.encode(X, cache = True)\n",
    "        Y_hat = self.decode(Y)\n",
    "        return Y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def get_glove_pre_trained_with_special_tokens(dim = 100):\n",
    "    glove_vectors = GloVe(name='6B', dim=dim)\n",
    "\n",
    "    pad_token = \"<pad>\"\n",
    "    pad_index = 0\n",
    "\n",
    "    eos_token = \"<eos>\"\n",
    "    eos_index = 1\n",
    "\n",
    "    bos_token = \"<bos>\"\n",
    "    bos_index = 2\n",
    "\n",
    "    glove_vocab = vocab(glove_vectors.stoi)\n",
    "\n",
    "    glove_vocab.insert_token(pad_token, pad_index)\n",
    "    glove_vocab.insert_token(eos_token, eos_index)\n",
    "    glove_vocab.insert_token(bos_token, bos_index)\n",
    "\n",
    "    glove_vocab.set_default_index(bos_index)\n",
    "\n",
    "    pretrained_embeddings = glove_vectors.vectors\n",
    "    pretrained_embeddings = torch.cat((torch.randn(3,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "    pretrained_embeddings[0] = torch.zeros(pretrained_embeddings.shape[1]) # Setting padding token embedding as 0s\n",
    "\n",
    "    return pretrained_embeddings, glove_vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def kaiming_custom_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.LayerNorm):\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Parameter):\n",
    "        if m.requires_grad:\n",
    "            init.kaiming_normal_(m, mode='fan_out', nonlinearity='relu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "pretrained_embeddings, glove_vocab = get_glove_pre_trained_with_special_tokens()\n",
    "attention_is_all_you_need = AttentionIsAllYouNeed(d_model = 100,\n",
    "                                                  d_k = 100,\n",
    "                                                  d_v = 100,\n",
    "                                                  h = 6,\n",
    "                                                  output = pretrained_embeddings.shape[0],\n",
    "                                                  number_of_encoder_stacks = 5,\n",
    "                                                  number_of_decoder_stacks = 5,\n",
    "                                                  padding_token=0)\n",
    "\n",
    "attention_is_all_you_need.init_weights(kaiming_custom_init)\n",
    "attention_is_all_you_need.init_embedding(pretrained_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6, 400003])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 5, 400003])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([[6, 90, 13, 100, 1, 0], [2, 7, 8, 60, 1, 0]])\n",
    "Y = torch.tensor([[51, 42, 967, 1, 0, 0], [2, 90, 56, 80, 1, 0]])\n",
    "\n",
    "x = torch.tensor([[6, 90, 13, 100, 1], [2, 7, 8, 60, 1]])\n",
    "y = torch.tensor([[51, 42, 967, 1, 0], [2, 90, 56, 80, 1]])\n",
    "\n",
    "output_1 = attention_is_all_you_need(X, Y)\n",
    "output_2 = attention_is_all_you_need(x, y)\n",
    "\n",
    "display(output_1.shape)\n",
    "display(output_2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0014, -0.0017,  0.0279,  ...,  0.0017, -0.0066,  0.0010],\n         [-0.0188,  0.0033,  0.0096,  ...,  0.0038, -0.0041, -0.0079],\n         [-0.0269, -0.0134, -0.0054,  ..., -0.0234, -0.0263, -0.0420],\n         [-0.0215,  0.0205, -0.0092,  ..., -0.0294, -0.0041, -0.0373],\n         [-0.0120,  0.0107, -0.0043,  ..., -0.0438, -0.0115, -0.0328],\n         [-0.0140,  0.0113, -0.0050,  ..., -0.0384, -0.0102, -0.0196]],\n\n        [[-0.0115, -0.0128, -0.0102,  ..., -0.0325, -0.0280, -0.0368],\n         [-0.0019, -0.0068,  0.0288,  ..., -0.0098,  0.0134, -0.0035],\n         [-0.0374,  0.0159,  0.0278,  ...,  0.0041, -0.0041,  0.0005],\n         [-0.0317,  0.0010,  0.0109,  ..., -0.0022, -0.0206, -0.0242],\n         [-0.0182,  0.0171, -0.0084,  ..., -0.0301, -0.0033, -0.0379],\n         [-0.0140,  0.0113, -0.0050,  ..., -0.0384, -0.0102, -0.0196]]],\n       grad_fn=<ViewBackward0>)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def _sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"Perform softmax operation by masking elements on the last axis.\n",
    "\n",
    "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
    "    # X: 3D tensor, valid_lens: 1D or 2D tensor\n",
    "\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # On the last axis, replace masked elements with a very large negative\n",
    "        # value, whose exponentiation outputs 0\n",
    "        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 5])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[0, 1, 2, 3, 4]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[ True,  True,  True, False, False],\n        [ True,  True, False, False, False]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[                 1,                  2,                  3,\n         -10000000000000000, -10000000000000000],\n        [                 4,                  5, -10000000000000000,\n         -10000000000000000, -10000000000000000]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_lens = torch.tensor([3, 2])\n",
    "value = -1.e16\n",
    "\n",
    "X = torch.tensor([[1, 2, 3, 0, 0], [4, 5, 0, 0, 0]])\n",
    "maxlen = X.size(1)\n",
    "mask = torch.arange((maxlen))[None, :] < valid_lens[:, None]\n",
    "X[~mask] = value\n",
    "\n",
    "display(X.shape)\n",
    "display(torch.arange((maxlen))[None, :])\n",
    "display(torch.arange((maxlen))[None, :] < valid_lens[:, None])\n",
    "display(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 5])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([3, 2, 1, 3, 3, 3])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00, -1.0000e+06, -1.0000e+06],\n        [ 1.0000e+00,  1.0000e+00, -1.0000e+06, -1.0000e+06, -1.0000e+06],\n        [ 1.0000e+00, -1.0000e+06, -1.0000e+06, -1.0000e+06, -1.0000e+06],\n        [ 1.0000e+00,  1.0000e+00,  1.0000e+00, -1.0000e+06, -1.0000e+06],\n        [ 1.0000e+00,  1.0000e+00,  1.0000e+00, -1.0000e+06, -1.0000e+06],\n        [ 1.0000e+00,  1.0000e+00,  1.0000e+00, -1.0000e+06, -1.0000e+06]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[[0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n\n        [[0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000]]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_lens = torch.tensor([[3, 2, 1], [3, 3, 3]])\n",
    "value = -1.e16\n",
    "\n",
    "X = torch.ones(2, 3, 5)\n",
    "\n",
    "shape = X.shape\n",
    "# display(valid_lens.dim())\n",
    "# display(torch.repeat_interleave(valid_lens, shape[1]))\n",
    "display(X.reshape(-1, shape[-1]).shape)\n",
    "\n",
    "if valid_lens.dim() == 1:\n",
    "    valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "else:\n",
    "    valid_lens = valid_lens.reshape(-1)\n",
    "# On the last axis, replace masked elements with a very large negative\n",
    "# value, whose exponentiation outputs 0\n",
    "display(valid_lens)\n",
    "X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "display(X)\n",
    "display(nn.functional.softmax(X.reshape(shape), dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 6, 6])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 6, 6])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[[ True,  True,  True, False, False, False],\n         [ True,  True,  True, False, False, False],\n         [ True,  True,  True, False, False, False],\n         [ True,  True,  True, False, False, False],\n         [ True,  True,  True, False, False, False],\n         [ True,  True,  True, False, False, False]],\n\n        [[ True,  True,  True,  True, False, False],\n         [ True,  True,  True,  True, False, False],\n         [ True,  True,  True,  True, False, False],\n         [ True,  True,  True,  True, False, False],\n         [ True,  True,  True,  True, False, False],\n         [ True,  True,  True,  True, False, False]]])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[[0.3250, 0.2849, 0.3902, 0.0000, 0.0000, 0.0000],\n         [0.3572, 0.3377, 0.3051, 0.0000, 0.0000, 0.0000],\n         [0.3075, 0.3108, 0.3817, 0.0000, 0.0000, 0.0000],\n         [0.3352, 0.3525, 0.3123, 0.0000, 0.0000, 0.0000],\n         [0.3633, 0.3016, 0.3351, 0.0000, 0.0000, 0.0000],\n         [0.3345, 0.3327, 0.3327, 0.0000, 0.0000, 0.0000]],\n\n        [[0.2011, 0.2337, 0.2528, 0.3124, 0.0000, 0.0000],\n         [0.2570, 0.2572, 0.2337, 0.2521, 0.0000, 0.0000],\n         [0.2304, 0.2498, 0.2618, 0.2580, 0.0000, 0.0000],\n         [0.2510, 0.2636, 0.2366, 0.2488, 0.0000, 0.0000],\n         [0.2893, 0.2415, 0.2201, 0.2491, 0.0000, 0.0000],\n         [0.2442, 0.2662, 0.2391, 0.2505, 0.0000, 0.0000]]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 6\n",
    "d_k = 64\n",
    "\n",
    "# Simulate query (Q) and key (K) matrices\n",
    "Q = torch.rand(batch_size, seq_len, d_k)\n",
    "K = torch.rand(batch_size, seq_len, d_k)\n",
    "\n",
    "# Calculate attention scores\n",
    "attention_scores = torch.bmm(Q, K.transpose(1, 2)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "display(attention_scores.shape)\n",
    "\n",
    "# Create a mask for padding (1 for valid positions and 0 for padded positions)\n",
    "# For example, assume the first sequence has 3 valid tokens and the second has 4\n",
    "mask_v = torch.tensor([[True, True, True, False, False, False], [True, True, True, True, False, False]])\n",
    "mask = mask_v.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "display(mask.shape)\n",
    "display(mask)\n",
    "\n",
    "# Apply the mask to the attention scores\n",
    "masked_attention_scores = attention_scores.masked_fill_(~mask, float('-inf'))\n",
    "\n",
    "display(F.softmax(masked_attention_scores, dim = -1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([400000, 100])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([400003, 100])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([400003, 100])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glove_vectors = GloVe(name='6B', dim=100)\n",
    "\n",
    "pad_token = \"<pad>\"\n",
    "pad_index = 0\n",
    "\n",
    "eos_token = \"<eos>\"\n",
    "eos_index = 1\n",
    "\n",
    "bos_token = \"<bos>\"\n",
    "bos_index = 2\n",
    "\n",
    "glove_vocab = vocab(glove_vectors.stoi)\n",
    "\n",
    "glove_vocab.insert_token(pad_token, pad_index)\n",
    "# glove_vocab.set_default_index(pad_index)\n",
    "\n",
    "glove_vocab.insert_token(eos_token, eos_index)\n",
    "# glove_vocab.set_default_index(eos_index)\n",
    "\n",
    "glove_vocab.insert_token(bos_token, bos_index)\n",
    "# glove_vocab.set_default_index(bos_index)\n",
    "\n",
    "glove_vocab.set_default_index(bos_index)\n",
    "\n",
    "display(glove_vectors.vectors.shape)\n",
    "\n",
    "pretrained_embeddings = glove_vectors.vectors\n",
    "pretrained_embeddings = torch.cat((torch.randn(3,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
    "display(pretrained_embeddings.shape)\n",
    "pretrained_embeddings[0] = torch.zeros(pretrained_embeddings.shape[1]) # Setting padding token embedding as 0s\n",
    "display(pretrained_embeddings.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "400002"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_vocab.get_itos())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 7, 100])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 7, 7])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_dim = 100\n",
    "embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze = True, sparse=True)\n",
    "embedding.eval()\n",
    "pos_encoding = PositionalEncoding(encoding_dim)\n",
    "pos_encoding.eval()\n",
    "Linear = nn.Linear(encoding_dim, encoding_dim)\n",
    "\n",
    "\n",
    "X = embedding(torch.tensor([[0, 1, 2, 0, 0, 0, 0], [0, 1, 2, 0, 0, 0, 0]]))\n",
    "X = pos_encoding(X)\n",
    "X = Linear(X)\n",
    "display(X.shape)\n",
    "attention_scores = torch.bmm(X, X.transpose(1, 2)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "display(attention_scores.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1000, 100])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding.P.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 60, 32])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n           0.0000e+00,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  5.3317e-01,  ...,  1.0000e+00,\n           1.7783e-04,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  9.0213e-01,  ...,  1.0000e+00,\n           3.5566e-04,  1.0000e+00],\n         ...,\n         [ 4.3616e-01,  8.9987e-01,  5.9521e-01,  ...,  9.9984e-01,\n           1.0136e-02,  9.9995e-01],\n         [ 9.9287e-01,  1.1918e-01,  9.3199e-01,  ...,  9.9983e-01,\n           1.0314e-02,  9.9995e-01],\n         [ 6.3674e-01, -7.7108e-01,  9.8174e-01,  ...,  9.9983e-01,\n           1.0492e-02,  9.9994e-01]]])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_dim, num_steps = 32, 60\n",
    "pos_encoding = PositionalEncoding(encoding_dim)\n",
    "pos_encoding.eval()\n",
    "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
    "P = pos_encoding.P[:, :X.shape[1], :]\n",
    "display(P.shape)\n",
    "display(P)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "ModuleList(\n  (0-7): 8 x ModuleList(\n    (0-2): 3 x Linear(in_features=512, out_features=512, bias=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_attention = MultiHeadAttention(512, 512, 512, 8)\n",
    "multi_head_attention.linear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q: torch.Size([2, 5, 64])\n",
      "Shape of K: torch.Size([2, 5, 64])\n",
      "Shape of V: torch.Size([2, 5, 64])\n",
      "Shape of output:torch.Size([2, 5, 64])\n",
      "tensor([[[        nan,  4.0096e+37,  6.2351e+37, -4.2478e+36, -2.0465e+37,\n",
      "          -4.1833e+36,         nan,         nan, -7.8783e+36,  1.0117e+37,\n",
      "          -9.4423e+35,  2.0174e+36, -5.8751e+36, -3.1546e+36, -3.0629e+36,\n",
      "          -1.6364e+37, -1.8854e+36, -5.5364e+35,  3.2821e+36, -3.7999e+36,\n",
      "          -8.9872e+35, -2.5219e+36,  3.8568e+36, -5.8303e+36,  1.0008e+37,\n",
      "           4.1014e+35, -5.0816e+36, -1.4643e+35, -4.0584e+37, -1.0357e+38,\n",
      "                  nan, -3.9588e+36,  1.1894e+36,  9.2627e+36,         nan,\n",
      "           3.2849e+36, -2.2424e+36,  6.2773e+36,  6.5724e+36, -2.8173e+36,\n",
      "          -1.7648e+37, -4.5027e+37,  9.5633e+35, -3.9691e+37,  2.6361e+36,\n",
      "           6.8147e+36,  2.2129e+37,  4.7346e+36,  3.1635e+36,  1.1845e+36,\n",
      "          -9.1324e+36,         nan,  3.2725e+37, -2.1265e+37, -2.5488e+37,\n",
      "                  nan, -1.6300e+37, -9.5616e+36,         nan, -1.2026e+37,\n",
      "          -3.9547e+36, -6.9687e+36,         nan, -1.0574e+37],\n",
      "         [        nan,  4.5371e+37,  4.7310e+37,  5.4921e+35, -1.1456e+37,\n",
      "          -5.6767e+36,         nan,         nan, -1.7323e+37,  1.1040e+37,\n",
      "          -7.2874e+35,  2.3083e+35, -3.2761e+36, -1.7506e+36, -2.2463e+36,\n",
      "          -1.1745e+37, -2.2174e+36, -1.2140e+36,  3.5099e+36, -4.3533e+36,\n",
      "          -1.3467e+36, -2.7611e+36,  6.2095e+36, -5.3817e+36,  8.0789e+36,\n",
      "           1.7980e+36, -1.5847e+37, -7.4729e+35, -2.5404e+37, -7.9355e+37,\n",
      "                  nan, -8.5253e+35,  1.1945e+37,  6.3805e+36,         nan,\n",
      "          -4.4083e+35, -2.8747e+36,  6.0402e+36, -2.0758e+37, -2.3559e+36,\n",
      "          -1.8084e+37, -5.2724e+37,  1.5476e+36, -2.5422e+37,  1.9936e+36,\n",
      "           4.9472e+36,  2.3681e+37,  3.7612e+36,  2.3868e+36,  1.3099e+36,\n",
      "          -1.7271e+37,         nan,  3.9787e+37, -2.3462e+37, -3.1127e+37,\n",
      "                  nan, -7.4143e+36, -5.7982e+36,         nan, -9.0302e+36,\n",
      "          -2.3564e+36, -2.4159e+37,         nan, -1.0047e+37],\n",
      "         [        nan,  4.9118e+37,  2.8799e+37, -2.3690e+36, -1.3319e+37,\n",
      "          -6.3740e+36,         nan,         nan, -1.2797e+37,  1.8175e+37,\n",
      "           6.8685e+35,  1.9020e+36, -4.2108e+36, -4.3006e+35, -2.8865e+36,\n",
      "          -1.1824e+37, -1.8071e+36, -5.8824e+35,  7.4211e+36, -2.5073e+36,\n",
      "          -2.7051e+35, -3.2702e+36,  3.5792e+36, -5.2558e+36,  9.0414e+36,\n",
      "           3.1522e+36, -1.2399e+37, -1.6784e+35, -3.4883e+37, -4.8289e+37,\n",
      "                  nan, -3.7508e+35, -4.6989e+36,  5.9225e+36,         nan,\n",
      "           4.4778e+36, -3.5246e+36,  5.1440e+36, -3.7284e+37, -1.4928e+36,\n",
      "          -1.9490e+37, -2.9684e+37,  2.5439e+36, -3.7528e+37,  2.1151e+36,\n",
      "           4.8459e+36,  3.1743e+37,  5.6058e+36,  2.5647e+36,  1.6227e+36,\n",
      "          -2.3841e+37,         nan,  7.2269e+36, -2.1338e+37, -4.1046e+37,\n",
      "                  nan, -7.5939e+36, -7.1677e+36,         nan, -9.5367e+36,\n",
      "          -4.7869e+35, -2.0132e+37,         nan, -1.3228e+37],\n",
      "         [        nan,  4.2701e+37,  3.1278e+37, -3.4594e+36, -1.3173e+37,\n",
      "          -4.4869e+36,         nan,         nan, -2.0866e+37,  1.4397e+37,\n",
      "           9.2448e+35,  1.7016e+36, -3.9572e+36, -2.2918e+36, -3.2081e+36,\n",
      "          -1.2101e+37, -3.4974e+36, -1.4807e+35,  6.6339e+36, -3.5434e+36,\n",
      "          -5.6288e+35, -2.7698e+36,  3.6293e+36, -5.5168e+36,  9.3535e+36,\n",
      "           9.5465e+35, -2.0705e+37, -1.5194e+36, -2.7286e+37, -2.0721e+37,\n",
      "                  nan, -1.8357e+36,  3.2049e+37,  7.1670e+36,         nan,\n",
      "           4.6845e+36, -4.2058e+36,  6.2472e+36,  2.4124e+36, -2.6578e+36,\n",
      "          -2.2141e+37, -2.8636e+37, -4.1369e+35, -3.0506e+37,  1.9976e+36,\n",
      "           5.8713e+36,  3.0222e+37,  5.1576e+36,  3.6138e+36,  1.6406e+36,\n",
      "          -2.7575e+37,         nan, -4.5744e+36, -2.1539e+37, -2.7313e+37,\n",
      "                  nan, -8.7414e+36, -7.4574e+36,         nan, -8.2005e+36,\n",
      "           3.8115e+35, -2.6973e+37,         nan, -1.3051e+37],\n",
      "         [        nan,  2.8682e+37,  6.1103e+37, -2.6967e+36, -1.5549e+37,\n",
      "          -5.8104e+36,         nan,         nan, -1.0133e+37,  6.5978e+36,\n",
      "          -8.2512e+35,  1.2320e+36, -4.6589e+36, -3.4753e+36, -2.1134e+36,\n",
      "          -1.4487e+37, -3.2187e+36,  7.7062e+35,  3.4364e+36, -4.9016e+36,\n",
      "          -8.6521e+35, -4.1841e+36,  2.6152e+36, -7.9143e+36,  8.8688e+36,\n",
      "           2.0476e+36, -4.5180e+36,  1.5368e+35, -2.7410e+37, -9.4083e+37,\n",
      "                  nan, -2.1257e+36,  9.6171e+36,  8.8870e+36,         nan,\n",
      "           3.1058e+36, -5.2376e+36,  4.9070e+36,  3.7013e+37, -3.1266e+36,\n",
      "          -2.1147e+37, -3.5390e+37, -2.3136e+35, -3.0475e+37,  1.3876e+36,\n",
      "           5.2787e+36,  2.8096e+37,  6.7754e+36,  3.1925e+36,  1.3650e+36,\n",
      "          -2.2867e+37,         nan, -2.0622e+36, -2.0660e+37, -3.1112e+37,\n",
      "                  nan, -1.1481e+37, -8.1132e+36,         nan, -1.1277e+37,\n",
      "          -4.6646e+35, -9.7187e+36,         nan, -8.9855e+36]],\n",
      "\n",
      "        [[        nan, -6.7382e+37, -4.2625e+37, -2.0470e+36, -1.2120e+37,\n",
      "           6.9545e+36,         nan,         nan,  4.5927e+36, -4.6779e+36,\n",
      "           3.6045e+36,  3.8402e+36, -3.9906e+35,  4.0838e+36, -4.7419e+35,\n",
      "          -5.7820e+36, -3.2959e+36,  2.5794e+36,  1.2670e+37,  2.2927e+36,\n",
      "          -6.5024e+36,  3.9236e+36, -4.9213e+36,  4.4147e+36, -2.3720e+36,\n",
      "           8.0673e+34,  3.2192e+36,  8.3080e+36, -2.1957e+36,  1.1026e+38,\n",
      "                  nan, -4.4608e+36,  2.4272e+37,  1.6779e+36,         nan,\n",
      "           1.2393e+37, -3.2946e+36, -1.3854e+36,  1.0151e+38, -2.3405e+36,\n",
      "          -8.0749e+34,  6.3272e+37, -5.7680e+35, -2.0210e+37,  1.2589e+36,\n",
      "           3.9819e+36,  1.5783e+37, -1.7765e+37,  2.7154e+36,  5.9493e+34,\n",
      "          -7.5366e+37,         nan,  5.1530e+37, -1.2407e+37,  9.6505e+37,\n",
      "                  nan, -1.2620e+37, -4.3970e+36,         nan, -6.5372e+36,\n",
      "          -1.5062e+36,  5.9815e+37,         nan, -1.8907e+36],\n",
      "         [        nan, -4.7847e+37, -7.2829e+37, -4.0247e+36, -9.4325e+36,\n",
      "           3.2184e+36,         nan,         nan,  2.0933e+36, -4.4742e+36,\n",
      "           3.3286e+36,  3.7517e+36, -7.4822e+35,  3.7271e+36,  5.6983e+34,\n",
      "          -5.2446e+36, -5.6281e+35,  3.2002e+36,  1.6434e+37,  4.0984e+36,\n",
      "          -6.8866e+36,  9.5101e+35, -8.3455e+36,  3.3271e+36, -3.5104e+36,\n",
      "          -9.1216e+35, -1.4527e+36,  1.0200e+37, -9.2892e+36,  1.0743e+38,\n",
      "                  nan, -4.9266e+36,  2.4732e+37,  2.8699e+35,         nan,\n",
      "           1.8105e+37, -3.9720e+36, -4.2993e+36,  1.2451e+38, -9.3465e+35,\n",
      "           5.9127e+35,  9.2176e+37,  1.0130e+36, -1.8885e+37,  8.3359e+35,\n",
      "           2.3037e+36,  5.7416e+37, -2.1029e+37,  2.3048e+36, -8.0261e+35,\n",
      "          -6.6816e+37,         nan,  3.6136e+37, -6.5235e+36,  8.6220e+37,\n",
      "                  nan, -1.1122e+37, -4.8830e+36,         nan, -8.2444e+36,\n",
      "          -1.5866e+36,  5.5652e+37,         nan, -4.3248e+35],\n",
      "         [        nan, -7.7807e+37, -8.4701e+37, -1.5271e+35, -1.0586e+37,\n",
      "           4.2972e+36,         nan,         nan,  8.2462e+36, -7.3330e+36,\n",
      "           3.9321e+36,  3.5485e+36, -1.1267e+36,  4.2229e+36, -5.0422e+34,\n",
      "          -5.1021e+36, -1.5769e+36,  2.3742e+36,  2.1336e+37,  3.6011e+36,\n",
      "          -7.0191e+36,  5.1292e+36, -6.4630e+36,  4.9931e+36, -1.5905e+36,\n",
      "          -2.1721e+35,  5.5742e+36,  8.1162e+36, -1.1983e+37,  1.0641e+38,\n",
      "                  nan, -5.1742e+36,  2.3310e+37,  2.7715e+36,         nan,\n",
      "           1.9239e+37, -2.8520e+36,  4.8822e+35,  1.4534e+38, -2.0154e+36,\n",
      "          -4.1000e+35,  8.3717e+37,  2.9008e+36, -1.7059e+37,  3.5598e+36,\n",
      "           5.8412e+36,  5.2233e+35, -1.8547e+37,  3.5854e+36,  5.3653e+35,\n",
      "          -8.1522e+37,         nan,  6.3159e+37, -1.2448e+37,  8.7578e+37,\n",
      "                  nan, -1.1996e+37, -2.9783e+36,         nan, -5.9547e+36,\n",
      "          -3.2199e+35,  6.0936e+37,         nan,  1.4890e+35],\n",
      "         [        nan, -4.0866e+37, -8.1404e+35, -3.8771e+36, -1.2921e+37,\n",
      "           9.6882e+36,         nan,         nan,  7.4035e+35, -1.1025e+36,\n",
      "           9.3987e+35,  3.4053e+36, -1.0225e+36,  2.9446e+36,  4.6211e+35,\n",
      "          -6.9564e+36,  8.7896e+35,  1.3443e+36,  2.3434e+36,  2.0795e+36,\n",
      "          -7.1560e+36,  6.1440e+35, -6.0527e+36,  1.5701e+36, -5.3739e+36,\n",
      "           7.3904e+35,  8.8220e+35,  7.2547e+36,  3.1726e+36,  7.9941e+37,\n",
      "                  nan, -1.9231e+36,  2.5558e+37,  1.0059e+36,         nan,\n",
      "           6.1404e+36, -3.1408e+36, -2.3816e+36,  6.9959e+37, -1.8776e+36,\n",
      "          -3.5930e+35,  4.1430e+37,  4.6489e+36, -1.5787e+37, -1.7887e+36,\n",
      "           4.5677e+36,  5.2622e+37, -1.7067e+37,  1.2779e+36,  1.3825e+35,\n",
      "          -6.5667e+37,         nan,  4.8443e+37, -4.4556e+36,  7.9856e+37,\n",
      "                  nan, -1.3251e+37, -3.3514e+36,         nan, -8.7271e+36,\n",
      "          -1.4011e+36,  6.8786e+37,         nan,  3.4693e+36],\n",
      "         [        nan, -5.0943e+37, -2.2526e+37, -3.2216e+36, -1.1693e+37,\n",
      "           6.9668e+36,         nan,         nan,  1.3614e+37, -4.3622e+36,\n",
      "           3.3956e+36,  3.7700e+36, -5.9977e+35,  4.0461e+36,  3.0312e+35,\n",
      "          -6.0069e+36,  1.1386e+36,  2.6835e+36,  1.1526e+37,  3.6401e+36,\n",
      "          -6.6442e+36,  1.1696e+36, -6.7622e+36,  3.2996e+36, -3.9768e+36,\n",
      "          -1.0856e+36,  1.2781e+37,  8.2962e+36, -1.5192e+37,  1.4187e+38,\n",
      "                  nan, -5.2713e+36,  1.8595e+37,  1.2509e+36,         nan,\n",
      "           1.1996e+37, -2.0380e+36, -9.9744e+35,  1.1079e+38, -1.6160e+36,\n",
      "           1.6075e+36,  6.6058e+37,  1.6729e+36, -2.0665e+37,  2.1890e+36,\n",
      "           3.2580e+36,  4.0523e+37, -1.9129e+37,  3.1845e+36, -2.2442e+35,\n",
      "          -6.7577e+37,         nan,  4.7854e+37, -7.3919e+36,  9.2492e+37,\n",
      "                  nan, -1.2633e+37, -3.5836e+36,         nan, -7.0847e+36,\n",
      "          -2.8390e+36,  6.1240e+37,         nan,  9.7956e+35]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2    # Example batch size\n",
    "seq_length = 5    # Length of the sequence (number of tokens)\n",
    "d_k = 64         # Dimension of the keys (and queries)\n",
    "model_dim = 64  # Dimension of the model\n",
    "h = 8\n",
    "\n",
    "# Generate random tensors for Q, K, V\n",
    "Q = torch.randn(batch_size, seq_length, d_k)  # Queries\n",
    "K = torch.randn(batch_size, seq_length, d_k)  # Keys\n",
    "V = torch.randn(batch_size, seq_length, model_dim)  # Values\n",
    "\n",
    "# Print the shapes for confirmation\n",
    "print(\"Shape of Q:\", Q.shape)  # Expected: (batch_size, seq_length, d_k)\n",
    "print(\"Shape of K:\", K.shape)  # Expected: (batch_size, seq_length, d_k)\n",
    "print(\"Shape of V:\", V.shape)  # Expected: (batch_size, seq_length, model_dim)\n",
    "\n",
    "multi_head_attention = MultiHeadAttention(model_dim, d_k, model_dim, h)\n",
    "output = multi_head_attention(Q, K, V)\n",
    "print(f'Shape of output:{output.shape}')\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n",
      "tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "torch.Size([2, 5, 64])\n",
      "tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2    # Example batch size\n",
    "seq_length = 5    # Length of the sequence (number of tokens)\n",
    "d_k = 64         # Dimension of the keys (and queries)\n",
    "model_dim = d_k  # Dimension of the model\n",
    "h = 8\n",
    "\n",
    "# Generate random tensors for Q, K, V\n",
    "X = torch.randn(batch_size, seq_length, d_k)  # Queries\n",
    "encoder_stack = EncoderStack(model_dim, d_k, model_dim, h)\n",
    "encoder_output = encoder_stack(X)\n",
    "print(encoder_output.shape)\n",
    "print(encoder_output)\n",
    "\n",
    "decoder_stack = DecoderStack(model_dim, d_k, model_dim, h)\n",
    "decoder_output = decoder_stack(X, encoder_output, encoder_output)\n",
    "print(decoder_output.shape)\n",
    "print(decoder_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n",
      "tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2    # Example batch size\n",
    "seq_length = 5    # Length of the sequence (number of tokens)\n",
    "d_k = 64         # Dimension of the keys (and queries)\n",
    "model_dim = d_k  # Dimension of the model\n",
    "h = 8\n",
    "\n",
    "# Generate random tensors for Q, K, V\n",
    "X = torch.randn(batch_size, seq_length, d_k)\n",
    "Y = torch.randn(batch_size, seq_length, d_k)\n",
    "\n",
    "attention_is_all_you_need = AttentionIsAllYouNeed(model_dim, d_k, model_dim, h, 1, 1)\n",
    "output = attention_is_all_you_need(X, Y)\n",
    "print(output.shape)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.3862, 0.6138, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.2037, 0.3103, 0.4860, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0186, 0.0134, 0.0176, 0.9504, 0.0000, 0.0000, 0.0000],\n         [0.2284, 0.1735, 0.2044, 0.3937, 0.0000, 0.0000, 0.0000],\n         [0.2611, 0.1619, 0.1860, 0.3910, 0.0000, 0.0000, 0.0000],\n         [0.2990, 0.1558, 0.1674, 0.3778, 0.0000, 0.0000, 0.0000]],\n\n        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.4494, 0.5506, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.2418, 0.2702, 0.4879, 0.0000, 0.0000, 0.0000, 0.0000],\n         [0.1864, 0.2136, 0.2419, 0.3582, 0.0000, 0.0000, 0.0000],\n         [0.0125, 0.0194, 0.0199, 0.0142, 0.9341, 0.0000, 0.0000],\n         [0.1262, 0.1511, 0.1852, 0.1579, 0.3795, 0.0000, 0.0000],\n         [0.1348, 0.1535, 0.1783, 0.1525, 0.3809, 0.0000, 0.0000]]],\n       grad_fn=<SoftmaxBackward0>)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tensor([[[0.9736, 0.0072, 0.0056, 0.0136, 0.0000, 0.0000, 0.0000],\n         [0.1937, 0.3078, 0.2318, 0.2668, 0.0000, 0.0000, 0.0000],\n         [0.1389, 0.2116, 0.3315, 0.3180, 0.0000, 0.0000, 0.0000],\n         [0.0186, 0.0134, 0.0176, 0.9504, 0.0000, 0.0000, 0.0000],\n         [0.2284, 0.1735, 0.2044, 0.3937, 0.0000, 0.0000, 0.0000],\n         [0.2611, 0.1619, 0.1860, 0.3910, 0.0000, 0.0000, 0.0000],\n         [0.2990, 0.1558, 0.1674, 0.3778, 0.0000, 0.0000, 0.0000]],\n\n        [[0.3581, 0.2049, 0.1657, 0.1165, 0.1548, 0.0000, 0.0000],\n         [0.2021, 0.2476, 0.1825, 0.1317, 0.2361, 0.0000, 0.0000],\n         [0.1531, 0.1710, 0.3088, 0.1397, 0.2274, 0.0000, 0.0000],\n         [0.1455, 0.1668, 0.1888, 0.2797, 0.2192, 0.0000, 0.0000],\n         [0.0125, 0.0194, 0.0199, 0.0142, 0.9341, 0.0000, 0.0000],\n         [0.1262, 0.1511, 0.1852, 0.1579, 0.3795, 0.0000, 0.0000],\n         [0.1348, 0.1535, 0.1783, 0.1525, 0.3809, 0.0000, 0.0000]]],\n       grad_fn=<SoftmaxBackward0>)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = torch.tensor([[2, 3, 4, 1, 0, 0, 0], [6, 8, 24, 7, 1, 0, 0]])\n",
    "\n",
    "encoding_dim = 100\n",
    "embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze = True, sparse=True)\n",
    "embedding.eval()\n",
    "pos_encoding = PositionalEncoding(encoding_dim)\n",
    "pos_encoding.eval()\n",
    "Linear = nn.Linear(encoding_dim, encoding_dim)\n",
    "attention = Attention()\n",
    "\n",
    "\n",
    "attention_is_all_you_need.create_mask(X)\n",
    "autoregressive_padding_mask = attention_is_all_you_need.autoregressive_padding_mask\n",
    "padding_mask = attention_is_all_you_need.padding_mask\n",
    "\n",
    "X_ = embedding(X)\n",
    "X_ = pos_encoding(X_)\n",
    "X_ = Linear(X_)\n",
    "\n",
    "attention.set_mask(autoregressive_padding_mask)\n",
    "auto_X = attention(X_, X_, X_, torch.tensor(encoding_dim))\n",
    "attention.set_mask(padding_mask)\n",
    "pad_X = attention(X_, X_, X_, torch.tensor(encoding_dim))\n",
    "\n",
    "\n",
    "display(auto_X)\n",
    "display(pad_X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}